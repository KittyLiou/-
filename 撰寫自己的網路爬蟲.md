# 什麼是網路爬蟲
在介紹如何撰寫自己的網路爬蟲前，先稍微說明一下甚麼叫做網路爬蟲，在對資料進行分析前最重要的就是要先有資料!!!而資料要從那裡來呢?最方便的途徑就是網路。然而網路上的資料那麼多，假設我希望得到某家商店的所有物品的價格，用手動的一個一個對商品價格複製貼上絕對不會是個好辦法，這時就需要網路爬蟲的幫忙了。
簡單而言，網路爬蟲的目的就是要自動化從網路上蒐集資料的過程，節省手動蒐集資料的時間。
# 套件安裝
本篇repo使用Python作為撰寫網路爬蟲的語言，在開始撰寫爬蟲程式之前我們需要先安裝相關套件，在此我們需要安裝requests和BeautifulSoup4
###安裝requests
`pip install requests`
###安裝BeautifulSoup4
`pip install BeautifulSoup4`
#爬蟲實例
這邊我以抓取 http://www.hm.com/us/products/search?q=romper 這個網頁裡所有的價格作為範例，來解釋如何使用requests級BeautifulSoup4來撰寫網路爬蟲
###import相關套件
```python
import requests
from bs4 import BeautifulSoup
```
###使用requests抓取網頁內容
![alt text][image]
[image]: https://github.com/KittyLiou/Crawler-Tutorial/blob/master/%E5%9C%96%E7%A4%BA.png "圖示"
首先我們先到 http://www.hm.com/us/products/search?q=romper 頁面，按右鍵點選"檢查"，點選"Network"，再點選"Doc"，這時按F5重新整理，點選第一個結果(如上圖所示)，這邊我們會看到<br>

Request URL : http://www.hm.com/us/products/search?q=romper <br>
Request Method : GET <br>

Request URL就是我們所要request的網址，而GET則是request的方式，因此下列的程式碼就是使用requests來抓取該網頁的內容<br>
```python
query_link = 'http://www.hm.com/us/products/search?q=romper'
res = requests.get(query_link)
```
然而到目前為止我們只是抓到了網頁內容，相當於抓到了網頁原始碼，但我們要怎麼取出該網頁裡面我們有興趣的部分呢?
###使用BeautifulSoup4剖析網頁內容
我們要以BeautifulSoup4來分析我們剛取得的網頁，因此加入下列程式碼<br>
`soup = BeautifulSoup(res.text, "html.parser")`<br>
在BeautifulSoup4中我們可以藉由select的方式來取得我們有興趣的tag內容，其中又分為id跟class兩種不同方式，兩者的取得方式分別如下：<br>
select('.class-name')<br>
select('#id-name')<br>
由於我們希望抓取的只有價格的部分，而從網頁原始碼中我們可以看到，價錢被包在一個class名稱為price的tag裡，因此以下的程式碼便是抓取出該網頁中所有的價格資訊
```python
for price in soup.select('.price'):
    print(price) 
```
然而執行程式就會發現抓取到的價格資訊並非是單純的價格而已，而是包含了tag名稱，因此我們在price後面加上.text，代表我們只要純文字的部分，修改之後的程式碼如下：<br>
```python
for price in soup.select('.price'):
    print(price.text) 
```
到此大功告成~短短幾行程式碼就完成了一隻簡易的網路爬蟲!
